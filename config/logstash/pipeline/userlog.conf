input {
	# beats {
	# 	port => 5044
	# }

	http {
		port => 50000
		codec => json
	}

	kafka {
        bootstrap_servers  => "10.0.4.12:9092"
        topics => "user-logs"
    }
}

filter {
    # Parse the event.original field
    json {
        source => "[event][original]"
        target => "parsed_data"  # Temporary field to store parsed data
    }

    # Replace the root fields with parsed data
    mutate {
        replace => { "[username]" => "%{[parsed_data][username]}" }
        replace => { "[IP]" => "%{[parsed_data][IP]}" }
        replace => { "[action]" => "%{[parsed_data][action]}" }
        replace => { "[useragent]" => "%{[parsed_data][useragent]}" }
        replace => { "[url]" => "%{[parsed_data][url]}" }
        replace => { "[data]" => "%{[parsed_data][data]}" }
    }

    # Remove unnecessary fields
    mutate {
        remove_field => ["event", "parsed_data", "message"]
    }
}

output {
	elasticsearch {
		hosts => "elasticsearch:9200"
		# user => "logstash_internal"
		# password => "${LOGSTASH_INTERNAL_PASSWORD}"
		index => "user-logs"
	}
	
	stdout {
        codec => rubydebug
    }
}
