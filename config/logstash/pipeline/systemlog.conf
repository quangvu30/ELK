input {
	# beats {
	# 	port => 5044
	# }

	http {
		port => 5000
		codec => plain
	}
	# kafka {
    #     bootstrap_servers  => "192.168.1.6:9092"
    #     topics => "system-logs"
    # }
}

filter {
    # Extract fields using the grok filter
    grok {
        match => {
            "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{LOGLEVEL:log_level}\] \(%{DATA:service_name}\): %{GREEDYDATA:log_message}"
        }
    }

    # Optionally, convert the timestamp field to a proper @timestamp
    date {
        match => ["timestamp", "ISO8601"]
        target => "@timestamp"
    }

    # Remove unnecessary fields
    mutate {
        remove_field => ["event", "parsed_data", "host", "user_agent", "http", "url", "message"]
    }
}

output {
	elasticsearch {
		hosts => "elasticsearch:9200"
		# user => "logstash_internal"
		# password => "${LOGSTASH_INTERNAL_PASSWORD}"
		index => "system-logs-%{+YYYY.MM.dd}"
	}
	
	stdout {
        codec => rubydebug
    }
}
